{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 128)\n",
      "(40000, 10)\n",
      "(10000, 128)\n",
      "(10000, 10)\n",
      "(10000, 128)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from algorithms import *\n",
    "data = Data()\n",
    "data.print_shapes()\n",
    "X_train = data.train_data\n",
    "y_train = data.train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.test_data\n",
    "y_test = data.test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Mlp(learning_rate=0.001, batch_size= 128)\n",
    "nn.set_optimiser('Adam',[0.9,0.99])\n",
    "nn.set_batchNormalizer(momentum = MOMENTUM)\n",
    "nn.add_layer(128,512,\"relu\",1)\n",
    "nn.add_layer(512,256,\"relu\",1)\n",
    "nn.add_layer(256,128,\"relu\",1)\n",
    "nn.add_layer(128,64,\"relu\",1)\n",
    "\n",
    "nn.add_layer(64,10,\"softmax\",1)\n",
    "### Try different learning rate and epochs\n",
    "\n",
    "#print('loss:%f'%MSE[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 1.7749307035826978  Time (sec): 15.06670594215393\n",
      "Epoch: 2  Training Loss: 1.4541153024733997  Time (sec): 13.25355839729309\n",
      "Epoch: 3  Training Loss: 1.3215745274851338  Time (sec): 13.353294134140015\n",
      "Epoch: 4  Training Loss: 1.2268277483896628  Time (sec): 13.125893592834473\n",
      "Epoch: 5  Training Loss: 1.1507305725529613  Time (sec): 14.503250360488892\n",
      "Epoch: 6  Training Loss: 1.0857966485703407  Time (sec): 12.889497518539429\n",
      "Epoch: 7  Training Loss: 1.0313461320202186  Time (sec): 14.662820816040039\n",
      "Epoch: 8  Training Loss: 0.9816254820630309  Time (sec): 12.633218050003052\n",
      "Epoch: 9  Training Loss: 0.9384289531771995  Time (sec): 14.176086902618408\n",
      "Epoch: 10  Training Loss: 0.8961517733695238  Time (sec): 16.067351579666138\n",
      "Epoch: 11  Training Loss: 0.8646208235265457  Time (sec): 14.354614973068237\n",
      "Epoch: 12  Training Loss: 0.8325621180836986  Time (sec): 26.71643900871277\n",
      "Epoch: 13  Training Loss: 0.8053755597526583  Time (sec): 17.062377452850342\n",
      "Epoch: 14  Training Loss: 0.7785985191972596  Time (sec): 14.763710260391235\n",
      "Epoch: 15  Training Loss: 0.7537055480491467  Time (sec): 20.476375818252563\n",
      "Epoch: 16  Training Loss: 0.7318008189377679  Time (sec): 15.986713171005249\n",
      "Epoch: 17  Training Loss: 0.7147666209336361  Time (sec): 28.50235652923584\n",
      "Epoch: 18  Training Loss: 0.6979726637036193  Time (sec): 34.58912444114685\n",
      "Epoch: 19  Training Loss: 0.6775600477190057  Time (sec): 33.87932109832764\n",
      "Epoch: 20  Training Loss: 0.6633967879278968  Time (sec): 24.575679302215576\n",
      "Epoch: 21  Training Loss: 0.652089139644359  Time (sec): 18.452486753463745\n",
      "Epoch: 22  Training Loss: 0.6407073621367417  Time (sec): 18.610499620437622\n",
      "Epoch: 23  Training Loss: 0.6231000967750708  Time (sec): 14.970914363861084\n",
      "Epoch: 24  Training Loss: 0.6188485341579951  Time (sec): 16.104952096939087\n",
      "Epoch: 25  Training Loss: 0.6056979901666268  Time (sec): 15.854869604110718\n",
      "Epoch: 26  Training Loss: 0.5972579951646627  Time (sec): 17.020183324813843\n",
      "Epoch: 27  Training Loss: 0.5909616374942268  Time (sec): 14.978301763534546\n",
      "Epoch: 28  Training Loss: 0.5792978755058454  Time (sec): 21.569180250167847\n",
      "Epoch: 29  Training Loss: 0.5748174091702688  Time (sec): 28.163851499557495\n",
      "Epoch: 30  Training Loss: 0.568094720474821  Time (sec): 34.60868573188782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.7749307 , 1.4541153 , 1.32157453, 1.22682775, 1.15073057,\n",
       "        1.08579665, 1.03134613, 0.98162548, 0.93842895, 0.89615177,\n",
       "        0.86462082, 0.83256212, 0.80537556, 0.77859852, 0.75370555,\n",
       "        0.73180082, 0.71476662, 0.69797266, 0.67756005, 0.66339679,\n",
       "        0.65208914, 0.64070736, 0.6231001 , 0.61884853, 0.60569799,\n",
       "        0.597258  , 0.59096164, 0.57929788, 0.57481741, 0.56809472]),\n",
       " 570.9912374019623)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, epochs= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98955"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.506"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.818 0.5498             loss 下降更快， learning rate 更小    0.95555  0.5027"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c882730db67e28db1e924ef806594fad4161f4a410f43aebd253948128b358f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
