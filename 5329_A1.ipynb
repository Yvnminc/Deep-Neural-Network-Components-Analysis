{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 128)\n",
      "(45000, 10)\n",
      "(5000, 128)\n",
      "(5000, 10)\n",
      "(10000, 128)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from algorithms import *\n",
    "from algorithms.MlpV2 import *\n",
    "data = Data()\n",
    "data.print_shapes()\n",
    "X_train = data.train_data\n",
    "y_train = data.train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.test_data\n",
    "y_test = data.test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MlpV2(learning_rate=0.003, batch_size= 100)\n",
    "nn.set_momentum(MOMENTUM)\n",
    "nn.set_batchNormalizer(momentum = MOMENTUM)\n",
    "nn.add_layer(128,512,\"relu\",1)\n",
    "nn.add_layer(512,256,\"relu\",1)\n",
    "nn.add_layer(256,128,\"relu\",1)\n",
    "nn.add_layer(128,64,\"relu\",1)\n",
    "nn.add_layer(64,10,\"softmax\",1)\n",
    "### Try different learning rate and epochs\n",
    "\n",
    "#print('loss:%f'%MSE[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1698074678658485"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 1.3713460231762746  Time (sec): 18.609264850616455\n",
      "Epoch: 2  Training Loss: 1.3561673532017327  Time (sec): 21.22451663017273\n",
      "Epoch: 3  Training Loss: 1.3384404141306288  Time (sec): 18.62694263458252\n",
      "Epoch: 4  Training Loss: 1.3220730963434704  Time (sec): 19.021316289901733\n",
      "Epoch: 5  Training Loss: 1.3101394724969846  Time (sec): 16.770113945007324\n",
      "Epoch: 6  Training Loss: 1.2969327218895075  Time (sec): 17.676764488220215\n",
      "Epoch: 7  Training Loss: 1.2871703094831957  Time (sec): 18.415409088134766\n",
      "Epoch: 8  Training Loss: 1.2704891782731123  Time (sec): 16.57616949081421\n",
      "Epoch: 9  Training Loss: 1.2605691025878136  Time (sec): 17.76727056503296\n",
      "Epoch: 10  Training Loss: 1.2534282758448227  Time (sec): 15.895767211914062\n",
      "Epoch: 11  Training Loss: 1.2418790537899975  Time (sec): 17.732576608657837\n",
      "Epoch: 12  Training Loss: 1.2305258143678137  Time (sec): 16.14672017097473\n",
      "Epoch: 13  Training Loss: 1.225655237139895  Time (sec): 17.085699558258057\n",
      "Epoch: 14  Training Loss: 1.2193539427947966  Time (sec): 16.95452642440796\n",
      "Epoch: 15  Training Loss: 1.2123368787060411  Time (sec): 14.880897283554077\n",
      "Epoch: 16  Training Loss: 1.209471896319776  Time (sec): 15.201394319534302\n",
      "Epoch: 17  Training Loss: 1.2058946180784333  Time (sec): 19.04619312286377\n",
      "Epoch: 18  Training Loss: 1.1974579054783725  Time (sec): 16.106404304504395\n",
      "Epoch: 19  Training Loss: 1.1891434001357826  Time (sec): 16.551660299301147\n",
      "Epoch: 20  Training Loss: 1.1838615861499153  Time (sec): 17.97203540802002\n",
      "Epoch: 21  Training Loss: 1.1803349358086683  Time (sec): 16.60468292236328\n",
      "Epoch: 22  Training Loss: 1.1765996363462565  Time (sec): 16.79795217514038\n",
      "Epoch: 23  Training Loss: 1.1746402578874373  Time (sec): 17.617281913757324\n",
      "Epoch: 24  Training Loss: 1.1681219212358398  Time (sec): 13.559914588928223\n",
      "Epoch: 25  Training Loss: 1.168722278421544  Time (sec): 16.339845180511475\n",
      "Epoch: 26  Training Loss: 1.1594544977206513  Time (sec): 15.754108667373657\n",
      "Epoch: 27  Training Loss: 1.1576602137898935  Time (sec): 17.60546064376831\n",
      "Epoch: 28  Training Loss: 1.1515467319097616  Time (sec): 16.107731103897095\n",
      "Epoch: 29  Training Loss: 1.1547410949693635  Time (sec): 18.290851831436157\n",
      "Epoch: 30  Training Loss: 1.148017902046184  Time (sec): 16.495007038116455\n",
      "Epoch: 31  Training Loss: 1.149659097630267  Time (sec): 16.119245529174805\n",
      "Epoch: 32  Training Loss: 1.151637217628137  Time (sec): 17.08563756942749\n",
      "Epoch: 33  Training Loss: 1.143223809164485  Time (sec): 15.880206108093262\n",
      "Epoch: 34  Training Loss: 1.1407629286440677  Time (sec): 17.381762742996216\n",
      "Epoch: 35  Training Loss: 1.142853655216627  Time (sec): 16.74509596824646\n",
      "Epoch: 36  Training Loss: 1.1392853356085582  Time (sec): 16.49091672897339\n",
      "Epoch: 37  Training Loss: 1.1381562288288773  Time (sec): 16.119967460632324\n",
      "Epoch: 38  Training Loss: 1.133072849250452  Time (sec): 19.213611602783203\n",
      "Epoch: 39  Training Loss: 1.1353358959307511  Time (sec): 13.464156866073608\n",
      "Epoch: 40  Training Loss: 1.1382280481471319  Time (sec): 17.466349601745605\n",
      "Epoch: 41  Training Loss: 1.1394893842035436  Time (sec): 15.940464973449707\n",
      "Epoch: 42  Training Loss: 1.1278814163663047  Time (sec): 16.512192249298096\n",
      "Epoch: 43  Training Loss: 1.1312498933799116  Time (sec): 13.254626989364624\n",
      "Epoch: 44  Training Loss: 1.1318557416126644  Time (sec): 16.863877296447754\n",
      "Epoch: 45  Training Loss: 1.134681279890042  Time (sec): 22.733521461486816\n",
      "Epoch: 46  Training Loss: 1.1314240358293814  Time (sec): 18.34597873687744\n",
      "Epoch: 47  Training Loss: 1.1345274197621105  Time (sec): 16.07591938972473\n",
      "Epoch: 48  Training Loss: 1.1287720062375834  Time (sec): 13.955069303512573\n",
      "Epoch: 49  Training Loss: 1.131389022780823  Time (sec): 13.825366020202637\n",
      "Epoch: 50  Training Loss: 1.1316526370696498  Time (sec): 15.207859992980957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.37134602, 1.35616735, 1.33844041, 1.3220731 , 1.31013947,\n",
       "       1.29693272, 1.28717031, 1.27048918, 1.2605691 , 1.25342828,\n",
       "       1.24187905, 1.23052581, 1.22565524, 1.21935394, 1.21233688,\n",
       "       1.2094719 , 1.20589462, 1.19745791, 1.1891434 , 1.18386159,\n",
       "       1.18033494, 1.17659964, 1.17464026, 1.16812192, 1.16872228,\n",
       "       1.1594545 , 1.15766021, 1.15154673, 1.15474109, 1.1480179 ,\n",
       "       1.1496591 , 1.15163722, 1.14322381, 1.14076293, 1.14285366,\n",
       "       1.13928534, 1.13815623, 1.13307285, 1.1353359 , 1.13822805,\n",
       "       1.13948938, 1.12788142, 1.13124989, 1.13185574, 1.13468128,\n",
       "       1.13142404, 1.13452742, 1.12877201, 1.13138902, 1.13165264])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, epochs= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329777777777777"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c882730db67e28db1e924ef806594fad4161f4a410f43aebd253948128b358f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
