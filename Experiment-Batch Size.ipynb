{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ee7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 128)\n",
      "(45000, 10)\n",
      "(5000, 128)\n",
      "(5000, 10)\n",
      "(10000, 128)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from algorithms import *\n",
    "from algorithms.MlpV2 import *\n",
    "data = Data()\n",
    "data.print_shapes()\n",
    "X_train = data.train_data\n",
    "y_train = data.train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bdd5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.test_data\n",
    "y_test = data.test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235498b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MlpV2(learning_rate=0.003, batch_size= 100)\n",
    "nn.set_momentum(0.9)\n",
    "nn.set_batchNormalizer()\n",
    "nn.add_layer(128,512,\"relu\",1)\n",
    "nn.add_layer(512,256,\"relu\",1)\n",
    "nn.add_layer(256,128,\"relu\",1)\n",
    "nn.add_layer(128,64,\"relu\",1)\n",
    "nn.add_layer(64,10,\"softmax\",1)\n",
    "### Try different learning rate and epochs\n",
    "\n",
    "#print('loss:%f'%MSE[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6569d89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1692766148618403"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11da128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 2.1951699268806673  Time (sec): 4.632705450057983\n",
      "Epoch: 2  Training Loss: 1.8844411039482323  Time (sec): 4.502886056900024\n",
      "Epoch: 3  Training Loss: 1.7883071117089  Time (sec): 4.761726140975952\n",
      "Epoch: 4  Training Loss: 1.7279501203821315  Time (sec): 4.783811807632446\n",
      "Epoch: 5  Training Loss: 1.683713167220673  Time (sec): 4.886353969573975\n",
      "Epoch: 6  Training Loss: 1.6484091381712813  Time (sec): 4.824772596359253\n",
      "Epoch: 7  Training Loss: 1.6213826398442346  Time (sec): 4.5674214363098145\n",
      "Epoch: 8  Training Loss: 1.5953825690045575  Time (sec): 4.640082597732544\n",
      "Epoch: 9  Training Loss: 1.5765759502198304  Time (sec): 4.614727258682251\n",
      "Epoch: 10  Training Loss: 1.5578315825432845  Time (sec): 4.6912782192230225\n",
      "Epoch: 11  Training Loss: 1.5386635548355774  Time (sec): 4.591536045074463\n",
      "Epoch: 12  Training Loss: 1.5212665055702608  Time (sec): 4.560343503952026\n",
      "Epoch: 13  Training Loss: 1.5050294462722624  Time (sec): 4.626044034957886\n",
      "Epoch: 14  Training Loss: 1.490285519747545  Time (sec): 4.659685373306274\n",
      "Epoch: 15  Training Loss: 1.4750128035312906  Time (sec): 4.605911493301392\n",
      "Epoch: 16  Training Loss: 1.4592436851901491  Time (sec): 4.5709686279296875\n",
      "Epoch: 17  Training Loss: 1.447031481174954  Time (sec): 4.765347242355347\n",
      "Epoch: 18  Training Loss: 1.4328177378640163  Time (sec): 4.804693698883057\n",
      "Epoch: 19  Training Loss: 1.4171645340454002  Time (sec): 5.192065477371216\n",
      "Epoch: 20  Training Loss: 1.4013325469717761  Time (sec): 4.921144485473633\n",
      "Epoch: 21  Training Loss: 1.388037144047982  Time (sec): 4.582358360290527\n",
      "Epoch: 22  Training Loss: 1.3710964083508175  Time (sec): 4.527920961380005\n",
      "Epoch: 23  Training Loss: 1.3577894397437906  Time (sec): 4.628666162490845\n",
      "Epoch: 24  Training Loss: 1.342201212136411  Time (sec): 4.603094100952148\n",
      "Epoch: 25  Training Loss: 1.3256991073504856  Time (sec): 4.647799968719482\n",
      "Epoch: 26  Training Loss: 1.3154509105948493  Time (sec): 4.6207966804504395\n",
      "Epoch: 27  Training Loss: 1.2976195036481653  Time (sec): 4.883528470993042\n",
      "Epoch: 28  Training Loss: 1.284890946601916  Time (sec): 4.590114593505859\n",
      "Epoch: 29  Training Loss: 1.2694586635868303  Time (sec): 4.5658886432647705\n",
      "Epoch: 30  Training Loss: 1.2572612722299936  Time (sec): 4.622084856033325\n",
      "Epoch: 31  Training Loss: 1.2429248014236427  Time (sec): 4.530303716659546\n",
      "Epoch: 32  Training Loss: 1.2328617490455798  Time (sec): 4.673101186752319\n",
      "Epoch: 33  Training Loss: 1.2209081386518272  Time (sec): 4.616069793701172\n",
      "Epoch: 34  Training Loss: 1.2097775383235467  Time (sec): 5.482984304428101\n",
      "Epoch: 35  Training Loss: 1.1986303956635154  Time (sec): 4.7742204666137695\n",
      "Epoch: 36  Training Loss: 1.1923462321211118  Time (sec): 4.623180627822876\n",
      "Epoch: 37  Training Loss: 1.1832294998373523  Time (sec): 4.958369255065918\n",
      "Epoch: 38  Training Loss: 1.1736870503125527  Time (sec): 4.6387598514556885\n",
      "Epoch: 39  Training Loss: 1.1659119346138356  Time (sec): 4.843053579330444\n",
      "Epoch: 40  Training Loss: 1.1679134755545202  Time (sec): 4.6704418659210205\n",
      "Epoch: 41  Training Loss: 1.1520503593837372  Time (sec): 4.720205307006836\n",
      "Epoch: 42  Training Loss: 1.151159059814094  Time (sec): 4.646467685699463\n",
      "Epoch: 43  Training Loss: 1.139977850831397  Time (sec): 4.5550689697265625\n",
      "Epoch: 44  Training Loss: 1.134747118709846  Time (sec): 4.561195611953735\n",
      "Epoch: 45  Training Loss: 1.131893423514695  Time (sec): 4.566832542419434\n",
      "Epoch: 46  Training Loss: 1.128491810508443  Time (sec): 4.559552431106567\n",
      "Epoch: 47  Training Loss: 1.1193736267665566  Time (sec): 4.60711932182312\n",
      "Epoch: 48  Training Loss: 1.115297205238818  Time (sec): 4.65235161781311\n",
      "Epoch: 49  Training Loss: 1.1174390415626712  Time (sec): 4.697621583938599\n",
      "Epoch: 50  Training Loss: 1.109528409076278  Time (sec): 4.647083044052124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.19516993, 1.8844411 , 1.78830711, 1.72795012, 1.68371317,\n",
       "       1.64840914, 1.62138264, 1.59538257, 1.57657595, 1.55783158,\n",
       "       1.53866355, 1.52126651, 1.50502945, 1.49028552, 1.4750128 ,\n",
       "       1.45924369, 1.44703148, 1.43281774, 1.41716453, 1.40133255,\n",
       "       1.38803714, 1.37109641, 1.35778944, 1.34220121, 1.32569911,\n",
       "       1.31545091, 1.2976195 , 1.28489095, 1.26945866, 1.25726127,\n",
       "       1.2429248 , 1.23286175, 1.22090814, 1.20977754, 1.1986304 ,\n",
       "       1.19234623, 1.1832295 , 1.17368705, 1.16591193, 1.16791348,\n",
       "       1.15205036, 1.15115906, 1.13997785, 1.13474712, 1.13189342,\n",
       "       1.12849181, 1.11937363, 1.11529721, 1.11743904, 1.10952841])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, epochs= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c5a8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7174888888888888"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
