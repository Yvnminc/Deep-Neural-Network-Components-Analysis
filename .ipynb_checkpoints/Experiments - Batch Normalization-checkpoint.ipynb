{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aafabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\James\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb055ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.train_data\n",
    "y_train = data.train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1291518",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = data.validation_data\n",
    "y_valid = data.validation_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71e8c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Running: True----------------------\n",
      "Epoch: 1  Training Loss: 2.3435554821431754  Time (sec): 3.997490167617798\n",
      "Epoch: 2  Training Loss: 1.933339217804634  Time (sec): 3.979417324066162\n",
      "Epoch: 3  Training Loss: 1.7688183448338965  Time (sec): 4.02702522277832\n",
      "Epoch: 4  Training Loss: 1.679801161846628  Time (sec): 4.011186838150024\n",
      "Epoch: 5  Training Loss: 1.6200979431968394  Time (sec): 3.930781364440918\n",
      "Epoch: 6  Training Loss: 1.5705882756291385  Time (sec): 3.977109432220459\n",
      "Epoch: 7  Training Loss: 1.5218121625105472  Time (sec): 4.007380247116089\n",
      "Epoch: 8  Training Loss: 1.478133533714733  Time (sec): 3.99153208732605\n",
      "Epoch: 9  Training Loss: 1.4320020871778532  Time (sec): 3.9421982765197754\n",
      "Epoch: 10  Training Loss: 1.3912170158154156  Time (sec): 3.814718008041382\n",
      "Epoch: 11  Training Loss: 1.3469521067383339  Time (sec): 3.8691189289093018\n",
      "Epoch: 12  Training Loss: 1.3085710856087358  Time (sec): 4.105190992355347\n",
      "Epoch: 13  Training Loss: 1.2717903346531487  Time (sec): 3.9881930351257324\n",
      "Epoch: 14  Training Loss: 1.240638505972247  Time (sec): 3.937121629714966\n",
      "Epoch: 15  Training Loss: 1.2167441937656138  Time (sec): 4.3068084716796875\n",
      "Epoch: 16  Training Loss: 1.2003502075036057  Time (sec): 3.9543604850769043\n",
      "Epoch: 17  Training Loss: 1.1802369838536235  Time (sec): 3.889284133911133\n",
      "Epoch: 18  Training Loss: 1.1620417939413938  Time (sec): 3.8816030025482178\n",
      "Epoch: 19  Training Loss: 1.1413521277884844  Time (sec): 3.899240732192993\n",
      "Epoch: 20  Training Loss: 1.134741669885059  Time (sec): 3.8790833950042725\n",
      "Epoch: 21  Training Loss: 1.1166055135381983  Time (sec): 3.8914332389831543\n",
      "Epoch: 22  Training Loss: 1.109691780610466  Time (sec): 3.8912229537963867\n",
      "Epoch: 23  Training Loss: 1.0935422405316952  Time (sec): 3.9053618907928467\n",
      "Epoch: 24  Training Loss: 1.0932542819185536  Time (sec): 3.9707446098327637\n",
      "Epoch: 25  Training Loss: 1.0820613507124837  Time (sec): 3.8475680351257324\n",
      "Epoch: 26  Training Loss: 1.078051540429368  Time (sec): 3.863637924194336\n",
      "Epoch: 27  Training Loss: 1.0701225355682131  Time (sec): 3.878232717514038\n",
      "Epoch: 28  Training Loss: 1.0638275730072695  Time (sec): 3.942897081375122\n",
      "Epoch: 29  Training Loss: 1.0615658052953039  Time (sec): 3.9200639724731445\n",
      "Epoch: 30  Training Loss: 1.0588301047959976  Time (sec): 4.006339073181152\n",
      "Epoch: 31  Training Loss: 1.0509298078832416  Time (sec): 3.764996290206909\n",
      "Epoch: 32  Training Loss: 1.0422388653022068  Time (sec): 3.8204941749572754\n",
      "Epoch: 33  Training Loss: 1.0446092747917946  Time (sec): 3.7754056453704834\n",
      "Epoch: 34  Training Loss: 1.0497548691982383  Time (sec): 3.8057141304016113\n",
      "Epoch: 35  Training Loss: 1.0501739108877535  Time (sec): 3.766517162322998\n",
      "Epoch: 36  Training Loss: 1.0516007882155491  Time (sec): 3.7355055809020996\n",
      "Epoch: 37  Training Loss: 1.0507992126090342  Time (sec): 3.7691171169281006\n",
      "Epoch: 38  Training Loss: 1.0469135082066994  Time (sec): 3.8211731910705566\n",
      "Epoch: 39  Training Loss: 1.0498081222000424  Time (sec): 3.846895456314087\n",
      "Epoch: 40  Training Loss: 1.0465241388678834  Time (sec): 3.7615747451782227\n",
      "Epoch: 41  Training Loss: 1.0493800535319884  Time (sec): 3.7809207439422607\n",
      "Epoch: 42  Training Loss: 1.045710959881121  Time (sec): 3.8486557006835938\n",
      "Epoch: 43  Training Loss: 1.037529355549267  Time (sec): 3.7818377017974854\n",
      "Epoch: 44  Training Loss: 1.038963455480038  Time (sec): 3.865936517715454\n",
      "Epoch: 45  Training Loss: 1.0377991593173126  Time (sec): 3.9162065982818604\n",
      "Epoch: 46  Training Loss: 1.0351760628630042  Time (sec): 3.8642003536224365\n",
      "Epoch: 47  Training Loss: 1.0392161360681018  Time (sec): 3.8545081615448\n",
      "Epoch: 48  Training Loss: 1.0357220337739768  Time (sec): 3.8909780979156494\n",
      "Epoch: 49  Training Loss: 1.030025509530776  Time (sec): 3.867053270339966\n",
      "Epoch: 50  Training Loss: 1.0287016252929866  Time (sec): 3.801907777786255\n",
      "-----------------Running: False----------------------\n",
      "Epoch: 1  Training Loss: 2.2959744862400564  Time (sec): 2.343369960784912\n",
      "Epoch: 2  Training Loss: 2.239181805796968  Time (sec): 2.3089890480041504\n",
      "Epoch: 3  Training Loss: 2.125439806904932  Time (sec): 2.331543207168579\n",
      "Epoch: 4  Training Loss: 1.9301114741716083  Time (sec): 2.3212430477142334\n",
      "Epoch: 5  Training Loss: 1.7757323570513843  Time (sec): 2.321493625640869\n",
      "Epoch: 6  Training Loss: 1.6879220316044627  Time (sec): 2.3286266326904297\n",
      "Epoch: 7  Training Loss: 1.623136353414717  Time (sec): 2.305232286453247\n",
      "Epoch: 8  Training Loss: 1.5699012518467876  Time (sec): 2.326087236404419\n",
      "Epoch: 9  Training Loss: 1.522750141680123  Time (sec): 2.3199989795684814\n",
      "Epoch: 10  Training Loss: 1.4785370101750308  Time (sec): 2.308784246444702\n",
      "Epoch: 11  Training Loss: 1.4373996356324408  Time (sec): 2.3309857845306396\n",
      "Epoch: 12  Training Loss: 1.398633743335889  Time (sec): 2.300570487976074\n",
      "Epoch: 13  Training Loss: 1.3587917374314833  Time (sec): 2.3032760620117188\n",
      "Epoch: 14  Training Loss: 1.3225734451863531  Time (sec): 2.2685799598693848\n",
      "Epoch: 15  Training Loss: 1.2869339493474379  Time (sec): 2.270235776901245\n",
      "Epoch: 16  Training Loss: 1.250417148587532  Time (sec): 2.2916018962860107\n",
      "Epoch: 17  Training Loss: 1.2171011805229082  Time (sec): 2.3059470653533936\n",
      "Epoch: 18  Training Loss: 1.1815330939440254  Time (sec): 2.236163377761841\n",
      "Epoch: 19  Training Loss: 1.1486287890145879  Time (sec): 2.364351987838745\n",
      "Epoch: 20  Training Loss: 1.1140117184402718  Time (sec): 2.3211779594421387\n",
      "Epoch: 21  Training Loss: 1.0818395393854001  Time (sec): 2.2698044776916504\n",
      "Epoch: 22  Training Loss: 1.0494466680045076  Time (sec): 2.253877878189087\n",
      "Epoch: 23  Training Loss: 1.0183269113674556  Time (sec): 2.3855018615722656\n",
      "Epoch: 24  Training Loss: 0.9867665250348603  Time (sec): 2.3482985496520996\n",
      "Epoch: 25  Training Loss: 0.9558851165062466  Time (sec): 2.4266879558563232\n",
      "Epoch: 26  Training Loss: 0.9255595940779002  Time (sec): 2.402024030685425\n",
      "Epoch: 27  Training Loss: 0.8945176122214499  Time (sec): 2.292142152786255\n",
      "Epoch: 28  Training Loss: 0.8648964930427158  Time (sec): 2.2875115871429443\n",
      "Epoch: 29  Training Loss: 0.8363094632582809  Time (sec): 2.263502359390259\n",
      "Epoch: 30  Training Loss: 0.8069567201148607  Time (sec): 2.2652065753936768\n",
      "Epoch: 31  Training Loss: 0.7771886945516527  Time (sec): 2.2932538986206055\n",
      "Epoch: 32  Training Loss: 0.7491837004348161  Time (sec): 2.2931571006774902\n",
      "Epoch: 33  Training Loss: 0.7185949162942469  Time (sec): 2.2922046184539795\n",
      "Epoch: 34  Training Loss: 0.6897993680742243  Time (sec): 2.3136703968048096\n",
      "Epoch: 35  Training Loss: 0.6632329113830012  Time (sec): 2.332529306411743\n",
      "Epoch: 36  Training Loss: 0.6347023930441842  Time (sec): 2.297788381576538\n",
      "Epoch: 37  Training Loss: 0.608177831846452  Time (sec): 2.3632640838623047\n",
      "Epoch: 38  Training Loss: 0.5799679410515163  Time (sec): 2.328608274459839\n",
      "Epoch: 39  Training Loss: 0.5547008713080979  Time (sec): 2.321312189102173\n",
      "Epoch: 40  Training Loss: 0.5280079724860394  Time (sec): 2.4286272525787354\n",
      "Epoch: 41  Training Loss: 0.501980886010567  Time (sec): 2.3263301849365234\n",
      "Epoch: 42  Training Loss: 0.47606087186262097  Time (sec): 2.3545868396759033\n",
      "Epoch: 43  Training Loss: 0.4500170263523131  Time (sec): 2.3417296409606934\n",
      "Epoch: 44  Training Loss: 0.4274662265249351  Time (sec): 2.277193784713745\n",
      "Epoch: 45  Training Loss: 0.40239713283843376  Time (sec): 2.3127360343933105\n",
      "Epoch: 46  Training Loss: 0.3774494538421824  Time (sec): 2.3160600662231445\n",
      "Epoch: 47  Training Loss: 0.35506003414654147  Time (sec): 2.3252861499786377\n",
      "Epoch: 48  Training Loss: 0.332364366787959  Time (sec): 2.2921249866485596\n",
      "Epoch: 49  Training Loss: 0.31017923789936613  Time (sec): 2.2843050956726074\n",
      "Epoch: 50  Training Loss: 0.29171006824685936  Time (sec): 2.339346170425415\n"
     ]
    }
   ],
   "source": [
    "from algorithms import Evals\n",
    "\n",
    "# Setup activation experiment\n",
    "bn = [True, False]\n",
    "\n",
    "eval_dict = Evals.set_exp(exps= bn, exp_name= 'batch_normalizer')\n",
    "eval_df = Evals.run_exp(exp_dict= eval_dict, epochs= 50, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1964ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>[2.3435554821431754, 1.933339217804634, 1.7688...</td>\n",
       "      <td>0.774525</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.770920</td>\n",
       "      <td>0.505255</td>\n",
       "      <td>0.773593</td>\n",
       "      <td>0.508308</td>\n",
       "      <td>0.756846</td>\n",
       "      <td>0.497747</td>\n",
       "      <td>194.862943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[2.2959744862400564, 2.239181805796968, 2.1254...</td>\n",
       "      <td>0.937225</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.937682</td>\n",
       "      <td>0.483239</td>\n",
       "      <td>0.937039</td>\n",
       "      <td>0.481445</td>\n",
       "      <td>0.937044</td>\n",
       "      <td>0.481089</td>\n",
       "      <td>115.852925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hyperparameters                                               loss  \\\n",
       "0             True  [2.3435554821431754, 1.933339217804634, 1.7688...   \n",
       "1            False  [2.2959744862400564, 2.239181805796968, 2.1254...   \n",
       "\n",
       "   train_acc  valid_acc  train_precision  valid_precision  train_recall  \\\n",
       "0   0.774525     0.5057         0.770920         0.505255      0.773593   \n",
       "1   0.937225     0.4798         0.937682         0.483239      0.937039   \n",
       "\n",
       "   valid_recall  train_f1  valid_f1       times  \n",
       "0      0.508308  0.756846  0.497747  194.862943  \n",
       "1      0.481445  0.937044  0.481089  115.852925  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
